{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f78e0148390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn.functional import gumbel_softmax\n",
    "import torch.nn.functional as F \n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0, 0, 1, 0]])\n",
    "b = torch.rand(4)\n",
    "l = nn.Linear(4, 8)\n",
    "l2 = nn.Linear(8, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [-0.0099, -0.1511, -0.2061, -0.3390, -0.1029,  0.4527, -0.1949, -0.3493],\n",
       "        [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.weight.T * a.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000,  0.0000,  0.1600,  0.0000],\n",
       "        [-0.0000,  0.0000,  0.1422,  0.0000],\n",
       "        [ 0.0000,  0.0000, -0.2094, -0.0000],\n",
       "        [ 0.0000, -0.0000,  0.1068, -0.0000],\n",
       "        [-0.0000,  0.0000,  0.1941,  0.0000],\n",
       "        [-0.0000, -0.0000, -0.0446,  0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0135,  0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0819,  0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.weight.T * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand([64, 784])\n",
    "res = F.gumbel_softmax(b, tau=1, hard=True, dim=-1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3709,  1.9028,  0.0851, -0.9270], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295325/1988205471.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return -torch.tensor(torch.log(-torch.log(U + eps) + eps))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    U = torch.rand(shape).cuda()\n",
    "    return -torch.tensor(torch.log(-torch.log(U + eps) + eps))\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    print(sample_gumbel(logits.size()))\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "def gumbel_softmax(logits, topk, temperature):\n",
    "    \"\"\"\n",
    "    input: [*, n_class]\n",
    "    return: [*, n_class] an one-hot vector\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    shape = y.size()\n",
    "    ind = y.topk(topk).indices\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.unsqueeze(0), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    return (y_hard - y).detach() + y\n",
    "\n",
    "# import math\n",
    "# print(gumbel_softmax(Variable(torch.cuda.FloatTensor([[math.log(0.1), math.log(0.4), math.log(0.3), math.log(0.2)]] * 20000)),     0.8).sum(dim=0))\n",
    "\n",
    "gumbel_softmax(torch.tensor([1, 0.13, 1, 0.03]).cuda(), 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    U = torch.rand(shape).cuda()\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "def gumbel_softmax(logits, k, temperature):\n",
    "    \"\"\"\n",
    "    ST-gumple-softmax\n",
    "    input: [*, n_class]\n",
    "    return: flatten --> [*, n_class] an one-hot vector\n",
    "    \"\"\"\n",
    "    y = logits\n",
    "\n",
    "    shape = y.size()\n",
    "    ind = y.topk(k).indices\n",
    "    print(ind)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.unsqueeze(0), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    # Set gradients w.r.t. y_hard gradients w.r.t. y\n",
    "    return (y_hard - y).detach() + y\n",
    "\n",
    "gumbel_softmax(torch.tensor([1, 0.13, 1, 0.03, 0, 0]).cuda(), 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7196, 0.3458, 0.8343, 0.6468, 0.5813, 0.5788, 0.2981, 0.5921, 0.2240,\n",
      "        0.3445, 0.8788, 0.4657, 0.8501, 0.3974, 0.7565, 0.4535, 0.7848, 0.6249,\n",
      "        0.2660, 0.7630])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand((20))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7196, 0.3458, 0.8343, 0.6468],\n",
      "        [0.5813, 0.5788, 0.2981, 0.5921],\n",
      "        [0.2240, 0.3445, 0.8788, 0.4657],\n",
      "        [0.8501, 0.3974, 0.7565, 0.4535],\n",
      "        [0.7848, 0.6249, 0.2660, 0.7630]])\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "t = t.reshape((5, -1))\n",
    "print(t)\n",
    "\n",
    "\n",
    "# tm = F.gumbel_softmax(t, 1, True, dim=-1)\n",
    "tm = torch.multinomial(t, 1)\n",
    "print(tm)\n",
    "tm.reshape((-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def deterministic_argmax(logits):\n",
    "    return torch.argmax(logits).unsqueeze(0).float()\n",
    "\n",
    "logits = torch.tensor([1.0, 2.0, 3.0])  # Example logits\n",
    "result = torch.zeros_like(logits)\n",
    "result[int(deterministic_argmax(logits).item())] = 1.0\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor([1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0])\n",
    "sparse = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 1.],\n",
       "        [2., 3., 1., 2.],\n",
       "        [3., 2., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits.reshape(sparse, -1)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.argmax(logits, dim=-1)\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295325/3240517964.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0, logits.numel()-1, sparse)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 3., 6., 9.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.range(0, logits.numel()-1, sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_295325/1556729594.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  ix = ix + torch.range(0, logits.numel()-1, logits.numel()/sparse)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 8.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = ix + torch.range(0, logits.numel()-1, logits.numel()/sparse)\n",
    "ix.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 3.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.reshape(-1)[ix.squeeze().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.zeros_like(logits)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 0., 1., 2., 3., 1., 2., 3., 2., 0., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits.reshape(-1)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand([16, 100])\n",
    "a2 = torch.rand([100, 16])\n",
    "b = torch.rand([1, 100])\n",
    "\n",
    "(b @ a.T @ a2.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-attention mask:\n",
      "tensor([[[[ True, False, False, False, False],\n",
      "          [ True,  True, False, False, False],\n",
      "          [ True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False],\n",
      "          [ True,  True,  True,  True,  True]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def create_self_attention_mask(seq_length):\n",
    "    # Create a lower triangular matrix with ones below the diagonal\n",
    "    mask = torch.tril(torch.ones(seq_length, seq_length)).unsqueeze(0).unsqueeze(1)\n",
    "    return mask.bool()\n",
    "\n",
    "# Example usage:\n",
    "seq_length = 5\n",
    "self_attention_mask = create_self_attention_mask(seq_length)\n",
    "print(\"Self-attention mask:\")\n",
    "print(self_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(seq_length, seq_length)).bool()[:3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf],\n",
       "        [0., 0., -inf],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"Generate a mask to prevent attention to future positions.\"\"\"\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "generate_square_subsequent_mask(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9023, 0.4406, 0.4752],\n",
       "         [0.1644, 0.1138, 0.7624],\n",
       "         [0.6273, 0.3581, 0.0987],\n",
       "         [0.2304, 0.8245, 0.7590],\n",
       "         [0.2209, 0.0981, 0.5909]]),\n",
       " tensor([[0.1240, 0.4452, 0.6205, 0.0330, 0.7096],\n",
       "         [0.8621, 0.0558, 0.3685, 0.2974, 0.6860],\n",
       "         [0.6334, 0.3797, 0.0690, 0.5151, 0.5579],\n",
       "         [0.4654, 0.4755, 0.6742, 0.2922, 0.7131],\n",
       "         [0.6609, 0.0234, 0.6790, 0.1374, 0.6518],\n",
       "         [0.2807, 0.3672, 0.1800, 0.6028, 0.1895],\n",
       "         [0.3497, 0.2175, 0.7435, 0.7842, 0.6028]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand([5, 3])\n",
    "b = torch.rand([7, 5])\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9023, 0.4406, 0.4752]],\n",
       "\n",
       "        [[0.1644, 0.1138, 0.7624]],\n",
       "\n",
       "        [[0.1644, 0.1138, 0.7624]],\n",
       "\n",
       "        [[0.1644, 0.1138, 0.7624]],\n",
       "\n",
       "        [[0.9023, 0.4406, 0.4752]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.tensor([0, 1, 1, 1, 0]).unsqueeze(1)\n",
    "print(s)\n",
    "a[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a sample tensor\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "\n",
    "# Select one element from each row\n",
    "selected_elements = tensor[torch.arange(tensor.size(0)), torch.tensor([2, 1, 2])]\n",
    "\n",
    "print(selected_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([2, 1, 2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(tensor.size(0)), torch.tensor([2, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.rand([1024, 25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  4,  8,  ..., 16,  8, 17])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ix = torch.argmax(i, dim=-1)\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "zch = torch.zeros(i.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected index [1, 1024] to be smaller than self [1024, 25] apart from dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mzch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# zch.scatter(0, ix.unsqueeze(0), 1)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected index [1, 1024] to be smaller than self [1024, 25] apart from dimension 0"
     ]
    }
   ],
   "source": [
    "zch.scatter(0, ix.unsqueeze(0), 1)\n",
    "# zch.scatter(0, ix.unsqueeze(0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0],\n",
       "        [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[0,0,0,0], [0,0,0,0]])\n",
    "b = torch.tensor([[1], [2]])\n",
    "\n",
    "r = a.scatter(1, b, 1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3)\n",
    "torch.cat([a for _ in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1224],\n",
       "         [1.1224],\n",
       "         [1.1224]],\n",
       "\n",
       "        [[0.8504],\n",
       "         [0.8504],\n",
       "         [0.8504]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(2, 3,3)\n",
    "b = torch.rand(2, 3,1)\n",
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3136],\n",
       "         [0.3769],\n",
       "         [0.4320]],\n",
       "\n",
       "        [[0.1902],\n",
       "         [0.0927],\n",
       "         [0.5675]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
